# spark experiment

step 1:
sudo apt update
sudo apt install openjdk-11-jdk -y
java -version

step 2:
cd ~
wget https://dlcdn.apache.org/spark/spark-3.5.7/spark-3.5.7-bin-hadoop3.tgz
tar -xzf spark-3.5.7.bin.hadoop3.tgz
mv spark-3.5.7.bin.hadoop3

step 3:
nano ~/.bashrc
export SPARK_HOME=$HOME/spark
export PATH=$PATH:$SPARK_HOME/sbin
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
source ~/.bashrc

step 4:
#check version
spark-shell --version

step 5:
mkdir input
echo "hello hadoop hello world" > input/file.txt

step 6:
spark-shell

val textFile = sc.textFile("input/file.txt")
val words = textFile.flatMap(line => line.split(" "))
val wordPairs = words.map(word => (word, 1))
val wordCounts = wordPairs.reduceByKey(_ + _)
wordCounts.collect().foreach(println)


